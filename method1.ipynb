{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import os\n",
    "import cv2 # type: ignore\n",
    "import tensorflow as tf# type: ignore\n",
    "from sklearn.model_selection import train_test_split# type: ignore\n",
    "from keras.preprocessing.image import ImageDataGenerator# type: ignore\n",
    "from tensorflow import keras# type: ignore\n",
    "from keras.models import Sequential# type: ignore\n",
    "from keras.layers import Dense, Dropout, Flatten# type: ignore\n",
    "from keras.layers import Conv2D, MaxPooling2D# type: ignore\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = os.listdir(\"D:/endtoend/gesturerecognition1/dataset/asl_alphabet_train/asl_alphabet_train/A\")\n",
    "B = os.listdir(\"D:/endtoend/gesturerecognition1/dataset/asl_alphabet_train/asl_alphabet_train/B\")\n",
    "C = os.listdir(\"D:/endtoend/gesturerecognition1/dataset/asl_alphabet_train/asl_alphabet_train/C\")\n",
    "D = os.listdir(\"D:/endtoend/gesturerecognition1/dataset/asl_alphabet_train/asl_alphabet_train/D\")\n",
    "E = os.listdir(\"D:/endtoend/gesturerecognition1/dataset/asl_alphabet_train/asl_alphabet_train/E\")\n",
    "F = os.listdir(\"D:/endtoend/gesturerecognition1/dataset/asl_alphabet_train/asl_alphabet_train/F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 3000\n",
      "Number of images: 3000\n",
      "Number of images: 3000\n",
      "Number of images: 3000\n",
      "Number of images: 3000\n",
      "Number of images: 3000\n"
     ]
    }
   ],
   "source": [
    "print('Number of images:', len(A))\n",
    "print('Number of images:', len(B))\n",
    "print('Number of images:', len(C))\n",
    "print('Number of images:',len(D))\n",
    "print('Number of images:',len(E))\n",
    "print('Number of images:', len(F))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_labels = [0]*3000 \n",
    "B_labels = [1]*3000 \n",
    "C_labels = [2]*3000 \n",
    "D_labels = [3]*3000 \n",
    "E_labels = [4]*3000 \n",
    "F_labels = [5]*3000 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=  A_labels + B_labels + C_labels + D_labels  + E_labels + F_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert images to numpy arrays+\n",
    "data = []\n",
    "A_path = \"D:/endtoend/gesturerecognition1/dataset/asl_alphabet_train/asl_alphabet_train/A/\"\n",
    "for img_file in A:\n",
    "\n",
    "  image = Image.open(A_path + img_file)\n",
    "  image = image.resize((128,128))\n",
    "  image = image.convert('RGB')\n",
    "  image = np.array(image)\n",
    "  data.append(image)\n",
    "\n",
    "B_path = \"D:/endtoend/gesturerecognition1/dataset/asl_alphabet_train/asl_alphabet_train/B/\"\n",
    "\n",
    "for img_file in B:\n",
    "\n",
    "  image = Image.open(B_path + img_file)\n",
    "  image = image.resize((128,128))\n",
    "  image = image.convert('RGB')\n",
    "  image = np.array(image)\n",
    "  data.append(image)\n",
    "\n",
    "C_path = \"D:/endtoend/gesturerecognition1/dataset/asl_alphabet_train/asl_alphabet_train/C/\"\n",
    "\n",
    "for img_file in C:\n",
    "\n",
    "  image = Image.open(C_path + img_file)\n",
    "  image = image.resize((128,128))\n",
    "  image = image.convert('RGB')\n",
    "  image = np.array(image)\n",
    "  data.append(image)\n",
    "\n",
    "D_path = \"D:/endtoend/gesturerecognition1/dataset/asl_alphabet_train/asl_alphabet_train/D/\"\n",
    "\n",
    "for img_file in D:\n",
    "\n",
    "  image = Image.open(D_path + img_file)\n",
    "  image = image.resize((128,128))\n",
    "  image = image.convert('RGB')\n",
    "  image = np.array(image)\n",
    "  data.append(image)  \n",
    "\n",
    "\n",
    "E_path = \"D:/endtoend/gesturerecognition1/dataset/asl_alphabet_train/asl_alphabet_train/E/\"\n",
    "\n",
    "for img_file in E:\n",
    "\n",
    "  image = Image.open(E_path + img_file)\n",
    "  image = image.resize((128,128))\n",
    "  image = image.convert('RGB')\n",
    "  image = np.array(image)\n",
    "  data.append(image)  \n",
    "\n",
    "F_path = \"D:/endtoend/gesturerecognition1/dataset/asl_alphabet_train/asl_alphabet_train/F/\"\n",
    "\n",
    "for img_file in F:\n",
    "\n",
    "  image = Image.open(F_path + img_file)\n",
    "  image = image.resize((128,128))\n",
    "  image = image.convert('RGB')\n",
    "  image = np.array(image)\n",
    "  data.append(image)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n",
      "18000\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data)\n",
    "Y = np.array(labels)\n",
    "print(len(X))\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(Y_train)\n",
    "y_test = keras.utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train.astype('float32')/255.0\n",
    "X_test_scaled = X_test.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mrina\\Anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\mrina\\Anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(128,128,3)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(16, kernel_size=(3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mrina\\Anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compile the neural network\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\mrina\\Anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\mrina\\Anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "394/394 [==============================] - 35s 84ms/step - loss: 1.0637 - acc: 0.5849\n",
      "Epoch 2/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.3607 - acc: 0.8729\n",
      "Epoch 3/10\n",
      "394/394 [==============================] - 33s 83ms/step - loss: 0.2102 - acc: 0.9254\n",
      "Epoch 4/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.1370 - acc: 0.9537\n",
      "Epoch 5/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.1049 - acc: 0.9636\n",
      "Epoch 6/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.0886 - acc: 0.9692\n",
      "Epoch 7/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.0731 - acc: 0.9738\n",
      "Epoch 8/10\n",
      "394/394 [==============================] - 31s 78ms/step - loss: 0.0685 - acc: 0.9757\n",
      "Epoch 9/10\n",
      "394/394 [==============================] - 32s 80ms/step - loss: 0.0568 - acc: 0.9798\n",
      "Epoch 10/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.0467 - acc: 0.9837\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 5s 24ms/step - loss: 0.0275 - acc: 0.9906\n",
      "Test Accuracy = 0.9905555844306946\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_scaled, Y_test)\n",
    "print('Test Accuracy =', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 4s 22ms/step\n",
      "5400\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.56       888\n",
      "           1       0.80      0.55      0.65       894\n",
      "           2       0.83      0.88      0.85       925\n",
      "           3       0.73      0.76      0.75       895\n",
      "           4       0.34      0.18      0.23       906\n",
      "           5       1.00      0.14      0.24       892\n",
      "\n",
      "    accuracy                           0.58      5400\n",
      "   macro avg       0.68      0.58      0.55      5400\n",
      "weighted avg       0.68      0.58      0.55      5400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
